The Strangler Fig Pattern
 - The strangler fig pattern is a software design pattern used to gradually replace
   or refactor a legacy system with a new system, piece by piece, without disrupting the
   existing functionality. This pattern gets its name from the way a strangler fig plant
   grows around an existing tree, slowly replacing it until the original tree is no longer
   needed.

   takeaways:
   - When to use The Strangler Fig Pattern:
     When you need to modernize a large or complex legacy system.
     When you want to avoid the risk associated with a complete system rewrite or "big bang" migration.
     When the legacy system needs to remain operational during the transition to the new system.


Docker Fundamentals
 - A docker container is a loosely isolated environment that allows us to build and run
   software packages. These software packages include the code and all dependencies to run
   the applications quickly and reliably on any computing environment. We call these packages
   as container images.


How to generate docker images
 - There several ways to generate docker images:
   * Using the traditional Dockerfile
   * Using Buildpacks
   * Using Google Jib
   * gradle jib OR
   * gradle jibDockerBuild

Running the jar file command:
 - java -jar build/libs/accounts-0.0.1-SNAPSHOT.jar

Building docker images commands
 - docker build . -t caito21/accounts:v0.0.1  ( -t stands for tag)
 - docker inspect image 15727fc9fd1c (inspect the image)

Build or Start docker container based on the image
 - docker run -p 8080:8080 caito21/accounts:v0.0.1

Port Mapping | Port Forwarding | Port Publishing
 - docker run -p 8080:8080

Buildpack use something called builders.
The builders are design to analise and build the application.
 - Buildpacks set
 - Stack
 - Lifecycle manager - assemble everything into a file (container image)
Buildpacks Lifecycle:
 - Detect - detect language or framework
 - Build - Fetch dependencies, compile code and configure runtime.

The most common docker commands:
 - docker images -> list all docker images present in the Docker Server
 - docker ps -> display or show all running containers
 - docker ps -a -> show all containers including running and stopped
 - docker image rm <image id>
 - docker image inspect <image id> -> display detailed imaged information
 - docker build . -t <image name> -> generate docker image based on Dockerfile settings
 - docker run -p [hostPort:ContainerPort] <image name> -> start a docker container based on a given image
 - docker container start <container id>
 - docker container stop <container id>
 - docker container pause <container id>
 - docker container unpause <container id>
 - docker container kill <container id>
 - docker container inspect <container id>
 - docker container restart <container id>
 - docker container logs <container id>
 - docker container logs -f <container id>
 - docker rm <container id>
 - docker container prune -> remove all stopped containers
 - docker image push [container_registry/username:tag] -> to push an image from a container registry
 - docker image pull [container_registry/username:tag] -> to pull an image from a container registry
 - docker image prune -> to remove all unused images
 - docker container stats
 - docker system prune [--all] -> remove stopped containers, dangling images, and unused networks, volumes and cache.
 - docker rmi <image id>
 - docker login -u <username>
 - docker logout -> log out from docker hub container registry
 - docker history <image name>
 - docker exec -it <container id> sh
 - docker compose up [-d]
 - docker compose down

The 15-Factor methodology
 1. One codebase, one application
 2. API First
 3. Dependency Management
 4. Design, Build, Release, Run.
 5. Configuration, Credentials & Code
 6. Logs
 7. Disposability
 8. Backing Services
 9. Environment Parity
10. Administrative Processes
11. Port Binding
12. Stateless Process
13. Concurrency
14. Telemetry
15. Authentication & Authorization

Spring Profiles:
 - Set up profiles via command line arguments (Program arguments)
   *  --spring.profiles.active=prod --build.version=1.1
 - Configure spring profiles via VM Options
   * -Dspring.profiles.active=prod -Dbuild.version=1.1
 - Configure spring profiles via Environment Variables
   * SPRING.PROFILES.ACTIVE=prod;BUILD.VERSION=1.4;

Steps to Refresh Config Files With Spring Actuator:
 - Add Spring Boot Actuator Dependency In the config client dependencies
 - Expose the endpoint in the application.yaml file:
    management:
        endpoints:
            web:
             exposure:
                include: refresh
 - Enable Refresh API from refresh endpoints: For instance localhost:8080/actuator/refresh

Spring Cloud Bus - links nodes of a distributed system with a lightweight message broker (AMQP or Kafka).
 - RabbitMQ docker installation command:
   * docker run -it --rm --name rabbitmq -p 5672:5672 -p 15672:15672 rabbitmq:4-management
 - Expose the endpoint in the application.yaml file:
     management:
        endpoints:
           web:
            exposure:
               include: busrefresh
 - Do the config changes and refresh all of them that are registered with rabbitmq at once, via endpoint:
   * http://localhost:8080/actuator/busrefresh

- **Spring Cloud Config Monitor**
  * When changes occur on GitHub fire a webhook to handle data change events on Spring Bus to refresh everything ...
- Install the hookdeck from website https://console.hookdeck.com/
- brew install hookdeck/hookdeck/hookdeck
- Login and start the CLI with those commands: hookdeck login --cli-key 2e4wkp8n48zocgmpgvxlyvaqj4k80g8qqubixrckoa1va6asnu
- hookdeck listen [the port of config server] Source: hookdeck listen 8071 Source --cli-path /monitor
- hookdeck logout - in case of login issues

- **Liveness and Readiness**
 - A liveness probe sends a signal that the container or application is either alive (passing) or dead (failing).
 - A readiness probe is used to know whether the container or an app that is being probed is ready to start
   receiving network traffic.
 - In Spring Boot applications, the actuator gathers the "Liveness" and "Readiness" information from the ApplicationAvailability
   interface and uses that information in dedicated health indicators: LivenessStateHealthIndicator and ReadinessStateHealthIndicator.
   These indicators are also shown on the global health indicator - "actuator/health". They are also exposed as separate HTTP Probes
   by using health groups:
    * "actuator/health/liveness"
    * "actuator/health/readiness"
    * http://localhost:8071/actuator/health
    * http://localhost:8071/actuator/health/liveness
    * http://localhost:8071/actuator/health/readiness

- Generating images with jib locally and push them to docker hub
  * gradle jibDockerBuild
  * docker image push docker.io/caito25/accounts:v0.0.1

- **Installing and Running hookdeck-cli with docker**
  * step 1: docker pull hookdeck/hookdeck-cli
  * step 2: docker run --rm -it hookdeck/hookdeck-cli version
  * step 3: hookdeck login --cli-key 38fmya3ek0oaebv8rnmw14l1t9hqzxec4nydyua86r7ejuin0u
  * step 4: hookdeck listen 8071 Source --cli-path /monitor

 - **PostgreSQL Containerization**
   * docker network create capferbank
   * docker run -p 5432:5432 --name accounts-db --network capferbank -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=pg-accounts-db -d postgres
   * docker run -p 5433:5432 --name cards-db --network capferbank -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=pg-cards-db -d postgres
   * docker run -p 5434:5432 --name loans-db --network capferbank -e POSTGRES_PASSWORD=postgres -e POSTGRES_DB=pg-loans-db -d postgres


 - **Microservices Traffic Concepts**
   * Microservice Network - the network where all your microservices are centralized in.
   * External Communication
   * Internal Communication - often uses the DNS, IP address, Hostname, etc.
   * Api Gateway handles security (authentication, authorization), Audit, Logging, etc.
   * External Clients are those that want to access your Microservices via API Gateway. For instance Client1, Client2, etc.

 - **Service Discovery && Registration Inside Microservices && Load Balancing**
   * Upstream Service - a service that depends on another service, for instance, the accounts service.
   * Downstream Service - the dependent service, for instance, the loans service. Here, the loans service is
     called the `The backing service`, since without it the accounts service wouldn't have succeeded request/response.
    - Monolithic Load Balancing Concepts:
      * Routing Tables
      * Health Checks
      * Primary Load Balancer
      * Secondary Load Balancer - the one that replaces the first one in case of failures or resilience.
   - **Limitations with traditional Load Balancers**:
      * Limited horizontal scalability and licenses costs
      * Single point of failure & centralized chokepoints

   - **Service Discovery Patter:**
     - involves tracking and store information about all running service instances in a service registry.
   - **Service Registry:**
     - Register a new service when a new instance of it is created, or remove it automatically when it's terminated.
   - Client-Side Service Discovery && Server-Side Service Discovery

 - **Service Discovery && Registration Inside Microservices** - is a way for applications and microservices
   locate each other in a network. This includes,
    * A central server (or servers) that maintain a global view of address.
    * Client / Microservices that connect to the central server to register their address when they start & ready.

 - Eureka Server Dashboard: http://localhost:8070/
 - Eureka Server (Config Server URL): http://localhost:8071/eurekaserver/default
 - Eureka Server All Apps urls: http://localhost:8070/eureka/apps
   * accounts app url: http://localhost:8070/eureka/apps/accounts
   * cards app url: http://localhost:8070/eureka/apps/cards
   * loans app url: http://localhost:8070/eureka/apps/loans

 The Spring Actuator Shutdown URL for microservices:
  accounts: http://localhost:8080/actuator/shutdown
  loans: http://localhost:8090/actuator/shutdown
  cards: http://localhost:9000/actuator/shutdown